{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preexisting Functions Needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_this_weeks_fights():\n",
    "\n",
    "    # Instantating constants\n",
    "\n",
    "    regex_weight = r\"\\d{3}\\sl\"\n",
    "    regex_reach = r'\\d{2}\"'\n",
    "    regex_dob = r',\\s\\d{4}'\n",
    "    regex_various_stats = r'\\d{1}\\.\\d{1,2}'\n",
    "    regex_various_stats_2 = r'\\d{1,2}%'\n",
    "    regex_record = r'\\d{1,2}-\\d{1,2}-\\d{1,2}'\n",
    "    year = dt.date.today().year\n",
    "    fight_data = pd.DataFrame()\n",
    "    options = Options()\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument(\"user-data-dir=/Users/hsinger24/Library/Application Support/Google/Chrome/Default1\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    options.add_argument('--disable-web-security')\n",
    "    options.add_argument('--allow-running-insecure-content')\n",
    "    options.add_argument(\"--disable-setuid-sandbox\")\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    driver.get('http://ufcstats.com/statistics/events/completed')\n",
    "    upcoming_card_data = pd.DataFrame(columns = ['name', 'weight', 'reach', 'age', 'slpm', 'sapm', 'td_avg', 'sub_avg', 'strk_acc', 'strk_def', 'td_acc',\n",
    "                                                'td_def', 'wins', 'losses'])\n",
    "\n",
    "    # Getting data for upcoming card\n",
    "\n",
    "    links_home_page = driver.find_elements(By.TAG_NAME, 'a') \n",
    "    del links_home_page[:6] \n",
    "    upcoming_card = links_home_page[0] \n",
    "    upcoming_card.click() \n",
    "    time.sleep(2)\n",
    "    links_upcoming_card = driver.find_elements(By.TAG_NAME, 'a') \n",
    "    del links_upcoming_card[:4]\n",
    "    for i in range(7):\n",
    "        del links_upcoming_card[-1]\n",
    "    for i, link in enumerate(links_upcoming_card):\n",
    "        if link.text=='View\\nMatchup':\n",
    "            del links_upcoming_card[i]\n",
    "    num_fighters = len(links_upcoming_card)\n",
    "    fighter = links_upcoming_card[0]\n",
    "    fighter.click()\n",
    "    for i in range(num_fighters):\n",
    "        if i!=0:\n",
    "            links_upcoming_card = driver.find_elements(By.TAG_NAME, 'a')\n",
    "            del links_upcoming_card[:4]\n",
    "            for j, link in enumerate(links_upcoming_card):\n",
    "                if link.text=='View\\nMatchup':\n",
    "                    del links_upcoming_card[j]\n",
    "            fighter= links_upcoming_card[i]\n",
    "            fighter.click() \n",
    "        time.sleep(2)\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        name = soup.find_all('span', class_ = 'b-content__title-highlight')[0].text.replace('\\n', '').replace(' ', '')\n",
    "        weight = float(re.findall(regex_weight, soup.prettify())[0].strip('l').replace(' ', ''))\n",
    "        reach = float(re.findall(regex_reach, soup.prettify())[1].strip('\"'))\n",
    "        dob = int(re.findall(regex_dob, soup.prettify())[0].strip(',').replace(' ', ''))\n",
    "        age = year - dob\n",
    "        slpm = float(re.findall(regex_various_stats, soup.prettify())[1])\n",
    "        sapm = float(re.findall(regex_various_stats, soup.prettify())[2])\n",
    "        td_avg = float(re.findall(regex_various_stats, soup.prettify())[3])\n",
    "        sub_avg = float(re.findall(regex_various_stats, soup.prettify())[4])\n",
    "        strk_acc = float(re.findall(regex_various_stats_2, soup.prettify())[0].strip('%'))\n",
    "        strk_def = float(re.findall(regex_various_stats_2, soup.prettify())[1].strip('%'))\n",
    "        td_acc = float(re.findall(regex_various_stats_2, soup.prettify())[2].strip('%'))\n",
    "        td_def = float(re.findall(regex_various_stats_2, soup.prettify())[3].strip('%'))\n",
    "        record = re.findall(regex_record, soup.prettify())[0]\n",
    "        record = record.split('-')\n",
    "        wins = float(record[0])\n",
    "        losses = float(record[1])\n",
    "        list_of_stats = [name, weight, reach, age, slpm, sapm, td_avg, sub_avg, strk_acc, strk_def, td_acc, td_def, wins, losses]\n",
    "        series = pd.Series(list_of_stats, index = upcoming_card_data.columns)\n",
    "        upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
    "        driver.back()\n",
    "    evens = upcoming_card_data.iloc[::2]\n",
    "    evens.reset_index(drop = True, inplace = True)\n",
    "    odds = upcoming_card_data.iloc[1::2]\n",
    "    odds.reset_index(drop = True, inplace = True)\n",
    "    final= pd.merge(evens, odds, left_index = True, right_index = True)\n",
    "    final.columns = ['fighter_1', 'weight_1', 'reach_1', 'age_1', 'slpm_1', 'sapm_1', 'td_avg_1', 'sub_avg_1', \n",
    "                    'strk_acc_1', 'strk_def_1', 'td_acc_1','td_def_1', 'wins_1', 'losses_1', 'fighter_2', 'weight_2', \n",
    "                    'reach_2', 'age_2', 'slpm_2', 'sapm_2', 'td_avg_2', 'sub_avg_2', 'strk_acc_2', 'strk_def_2', \n",
    "                    'td_acc_2','td_def_2', 'wins_2', 'losses_2']\n",
    "    final['result'] = -5\n",
    "    final['SUB_OVR']= 0\n",
    "    final['KO_OVR'] = 0\n",
    "    print(final.tail())\n",
    "    driver.quit()\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_data_prep(target):\n",
    "\n",
    "    # Importing data to train RF\n",
    "    data = pd.read_csv('mma_data.csv', index_col=0)\n",
    "\n",
    "    # Filtering out unwanted rows\n",
    "    data = data[data.slpm_2 + data.sapm_2 != 0]\n",
    "    data = data[data.slpm_1 + data.sapm_1 != 0]\n",
    "    data = data[data.result >= 0]\n",
    "\n",
    "    # Engineering some columns\n",
    "    data['strike_diff_1'] = data.slpm_1 - data.sapm_1\n",
    "    data['strike_diff_2'] = data.slpm_2 - data.sapm_2\n",
    "    data['strike_diff'] = data.strike_diff_1 - data.strike_diff_2\n",
    "    data['td_diff_1'] = data.td_acc_1 - data.td_def_1\n",
    "    data['td_diff_2'] = data.td_acc_2 - data.td_def_2\n",
    "    data['td_diff'] = data.td_diff_1 - data.td_diff_2\n",
    "    data['reach_diff'] = data.reach_1 - data.reach_2\n",
    "    data['age_diff'] = data.age_1 - data.age_2\n",
    "    data['slpm_diff'] = data.slpm_1 - data.slpm_2\n",
    "    data['sapm_diff'] = data.sapm_1 - data.sapm_2\n",
    "    data['td_acc_diff'] = data.td_acc_1 - data.td_acc_2\n",
    "    data['td_def_diff'] = data.td_def_1 - data.td_def_2\n",
    "    data['td_avg_diff'] = data.td_avg_1 - data.td_avg_2\n",
    "    data['sub_avg_diff'] = data.sub_avg_1 - data.sub_avg_2\n",
    "    data['strk_acc_diff'] = data.strk_acc_1 - data.strk_acc_2\n",
    "    data['strk_def_diff'] = data.strk_def_1 - data.strk_def_2\n",
    "    data['wins_diff'] = data.wins_1 - data.wins_2\n",
    "    data['losses_diff'] = data.losses_1 - data.losses_2\n",
    "    data['win_pct_1'] = data.wins_1/(data.losses_1 + data.wins_1)\n",
    "    data['win_pct_2'] = data.wins_2/(data.losses_2 + data.wins_2)\n",
    "    data['win_pct_diff'] = data.win_pct_1 - data.win_pct_2\n",
    "\n",
    "    # Droping unecessary columnns and scaling data\n",
    "    x_cols = ['reach_diff', 'age_diff', 'slpm_diff', 'sapm_diff', 'td_acc_diff', 'td_def_diff',\n",
    "                'td_avg_diff', 'sub_avg_diff', 'strk_acc_diff', 'strk_def_diff', 'wins_diff',\n",
    "                'losses_diff', 'win_pct_diff', 'weight_1', 'age_1', 'strike_diff', 'td_diff']\n",
    "    y_col = target\n",
    "\n",
    "    x, y = data[x_cols], data[y_col]\n",
    "    y = y.values.ravel()\n",
    "\n",
    "    return x, y, x_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid_search(model, param_grid, x, y, cv = 10):\n",
    "    # Running Grid Search\n",
    "    grid_search = GridSearchCV(model, param_grid, cv = cv)\n",
    "    grid_search.fit(x, y)\n",
    "    \n",
    "    # Outputting results\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def this_weeks_predictions(this_weeks_fights):\n",
    "    \n",
    "    # Getting x and y for models\n",
    "    x, y, x_cols = ml_data_prep(target = 'result')\n",
    "    x_scaled = StandardScaler().fit_transform(x)\n",
    "    x_ko, y_ko, x_cols = ml_data_prep(target = 'KO_OVR')\n",
    "    x_ko_scaled = StandardScaler().fit_transform(x_ko)\n",
    "    x_sub, y_sub, x_cols = ml_data_prep(target = 'SUB_OVR')\n",
    "    x_sub_scaled = StandardScaler().fit_transform(x_sub)\n",
    "\n",
    "    # Prep grid searches\n",
    "    # RF\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 3, stop = 15, num = 13)]\n",
    "    max_features = [int(x) for x in np.linspace(start = 3, stop = 10, num = 8)]\n",
    "    max_depth = [int(x) for x in np.linspace(start = 1, stop = 10, num = 10)]\n",
    "    param_grid_rf = {\n",
    "        'n_estimators' : n_estimators,\n",
    "        'max_features' : max_features,\n",
    "        'max_depth' : max_depth\n",
    "    }\n",
    "    # GB\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 3, stop = 15, num = 13)]\n",
    "    max_features = [int(x) for x in np.linspace(start = 3, stop = 10, num = 8)]\n",
    "    max_depth = [int(x) for x in np.linspace(start = 1, stop = 10, num = 10)]\n",
    "    param_grid_gb = {\n",
    "        'n_estimators' : n_estimators,\n",
    "        'max_features' : max_features,\n",
    "        'max_depth' : max_depth\n",
    "    }\n",
    "    # LR\n",
    "    c = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "    param_grid_lr = {\n",
    "        'C' : c\n",
    "    }\n",
    "    \n",
    "    # Saving best winner models from grid searches\n",
    "    rf_winner = create_grid_search(RandomForestClassifier(random_state = 0, class_weight = 'balanced'), param_grid_rf, cv = 10, x = x, y = y)\n",
    "    gb_winner = create_grid_search(GradientBoostingClassifier(random_state = 0), param_grid_gb, cv = 10, x = x, y = y)\n",
    "    lr_winner = create_grid_search(LogisticRegression(random_state = 0, class_weight = 'balanced', max_iter = 500), param_grid_lr, cv = 10, x = x_scaled, y = y)\n",
    "    rf_ko = create_grid_search(RandomForestClassifier(random_state = 0, class_weight = 'balanced'), param_grid_rf, cv = 10, x = x_ko, y = y_ko)\n",
    "    gb_ko = create_grid_search(GradientBoostingClassifier(random_state = 0), param_grid_gb, cv = 10, x = x_ko, y = y_ko)\n",
    "    lr_ko = create_grid_search(LogisticRegression(random_state = 0, class_weight = 'balanced', max_iter = 500), param_grid_lr, cv = 10, x = x_ko_scaled, y = y_ko)\n",
    "    rf_sub = create_grid_search(RandomForestClassifier(random_state = 0, class_weight = 'balanced'), param_grid_rf, cv = 10, x = x_sub, y = y_sub)\n",
    "    gb_sub = create_grid_search(GradientBoostingClassifier(random_state = 0), param_grid_gb, cv = 10, x = x_sub, y = y_sub)\n",
    "    lr_sub = create_grid_search(LogisticRegression(random_state = 0, class_weight = 'balanced', max_iter = 500), param_grid_lr, cv = 10, x = x_sub_scaled, y = y_sub)\n",
    "\n",
    "    # Filtering out fights with UFC newcomers\n",
    "    this_weeks_fights = this_weeks_fights[this_weeks_fights.slpm_2 + this_weeks_fights.sapm_2 != 0]\n",
    "    this_weeks_fights = this_weeks_fights[this_weeks_fights.slpm_1 + this_weeks_fights.sapm_1 != 0]\n",
    "\n",
    "    # Preparing prediction data & predicting\n",
    "    this_weeks_fights['strike_diff_1'] = this_weeks_fights.slpm_1 - this_weeks_fights.sapm_1\n",
    "    this_weeks_fights['strike_diff_2'] = this_weeks_fights.slpm_2 - this_weeks_fights.sapm_2\n",
    "    this_weeks_fights['strike_diff'] = this_weeks_fights.strike_diff_1 - this_weeks_fights.strike_diff_2\n",
    "    this_weeks_fights['td_diff_1'] = this_weeks_fights.td_acc_1 - this_weeks_fights.td_def_1\n",
    "    this_weeks_fights['td_diff_2'] = this_weeks_fights.td_acc_2 - this_weeks_fights.td_def_2\n",
    "    this_weeks_fights['td_diff'] = this_weeks_fights.td_diff_1 - this_weeks_fights.td_diff_2\n",
    "    this_weeks_fights['reach_diff'] = this_weeks_fights.reach_1 - this_weeks_fights.reach_2\n",
    "    this_weeks_fights['age_diff'] = this_weeks_fights.age_1 - this_weeks_fights.age_2\n",
    "    this_weeks_fights['slpm_diff'] = this_weeks_fights.slpm_1 - this_weeks_fights.slpm_2\n",
    "    this_weeks_fights['sapm_diff'] = this_weeks_fights.sapm_1 - this_weeks_fights.sapm_2\n",
    "    this_weeks_fights['td_acc_diff'] = this_weeks_fights.td_acc_1 - this_weeks_fights.td_acc_2\n",
    "    this_weeks_fights['td_def_diff'] = this_weeks_fights.td_def_1 - this_weeks_fights.td_def_2\n",
    "    this_weeks_fights['td_avg_diff'] = this_weeks_fights.td_avg_1 - this_weeks_fights.td_avg_2\n",
    "    this_weeks_fights['sub_avg_diff'] = this_weeks_fights.sub_avg_1 - this_weeks_fights.sub_avg_2\n",
    "    this_weeks_fights['strk_acc_diff'] = this_weeks_fights.strk_acc_1 - this_weeks_fights.strk_acc_2\n",
    "    this_weeks_fights['strk_def_diff'] = this_weeks_fights.strk_def_1 - this_weeks_fights.strk_def_2\n",
    "    this_weeks_fights['wins_diff'] = this_weeks_fights.wins_1 - this_weeks_fights.wins_2\n",
    "    this_weeks_fights['losses_diff'] = this_weeks_fights.losses_1 - this_weeks_fights.losses_2\n",
    "    this_weeks_fights['win_pct_1'] = this_weeks_fights.wins_1/(this_weeks_fights.losses_1 + this_weeks_fights.wins_1)\n",
    "    this_weeks_fights['win_pct_2'] = this_weeks_fights.wins_2/(this_weeks_fights.losses_2 + this_weeks_fights.wins_2)\n",
    "    this_weeks_fights['win_pct_diff'] = this_weeks_fights.win_pct_1 - this_weeks_fights.win_pct_2\n",
    "    \n",
    "    x_data_pred = this_weeks_fights[x_cols]\n",
    "\n",
    "    this_weeks_fights['Prediction_RF_Winner'] = rf_winner.predict_proba(x_data_pred)[:, 1]\n",
    "    this_weeks_fights['Prediction_GB_Winner'] = gb_winner.predict_proba(x_data_pred)[:, 1]\n",
    "    this_weeks_fights['Prediction_LR_Winner'] = lr_winner.predict_proba(x_data_pred)[:, 1]\n",
    "    this_weeks_fights['Prediction_RF_SUB'] = rf_sub.predict_proba(x_data_pred)[:, 1]\n",
    "    this_weeks_fights['Prediction_GB_SUB'] = gb_sub.predict_proba(x_data_pred)[:, 1]\n",
    "    this_weeks_fights['Prediction_LR_SUB'] = lr_sub.predict_proba(x_data_pred)[:, 1]\n",
    "    this_weeks_fights['Prediction_RF_KO'] = rf_ko.predict_proba(x_data_pred)[:, 1]\n",
    "    this_weeks_fights['Prediction_GB_KO'] = gb_ko.predict_proba(x_data_pred)[:, 1]\n",
    "    this_weeks_fights['Prediction_LR_KO'] = lr_ko.predict_proba(x_data_pred)[:, 1]\n",
    "\n",
    "    # Saving date and predicted data\n",
    "    this_weeks_fights['Date'] = dt.date.today()\n",
    "\n",
    "    return this_weeks_fights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Bets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Downloading: 100%|█████████████████| 8.79M/8.79M [00:01<00:00, 7.36MB/s]\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_8481/3244408514.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    }
   ],
   "source": [
    "# Instantiating webdriver\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "driver.get('https://www.actionnetwork.com/ufc/odds')\n",
    "\n",
    "# Getting odds table and formatting\n",
    "html = driver.page_source\n",
    "tables = pd.read_html(html)\n",
    "odds = tables[0]\n",
    "odds = odds.iloc[::2]\n",
    "odds.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating through to get each fighter's odds\n",
    "\n",
    "odds_df = pd.DataFrame(columns = ['Fighter_1', 'Fighter_2', 'Fighter_1_Odds', 'Fighter_2_Odds'])\n",
    "fighter_2_regex = r'^[A-Za-z]+\\s[A-Za-z]+'\n",
    "fighter_1_regex = r'[A-Za-z]+\\s[A-Za-z]+(?=[A-Za-z]*\\.)'\n",
    "for index, row in odds.iterrows():\n",
    "    # Getting fighter names\n",
    "    try:\n",
    "        fighter_2 = re.findall(fighter_2_regex, row.Scheduled)[0]\n",
    "        fighter_2 = fighter_2[:-1]\n",
    "        fighter_2_replace = fighter_2.split()[1]\n",
    "        fighter_1 = re.findall(fighter_1_regex, row.Scheduled)[1]\n",
    "        fighter_1 = fighter_1.replace(fighter_2_replace, \"\")[:-1]\n",
    "    except:\n",
    "        flag_regex = r'[^\\x00-\\x7F]'\n",
    "        names_string = re.sub(flag_regex, '', row.Scheduled)\n",
    "        fighter_2 = re.findall(fighter_2_regex, names_string)[0]\n",
    "        fighter_2 = fighter_2[:-1]\n",
    "        fighter_2_replace = fighter_2.split()[1]\n",
    "        fighter_1 = re.findall(fighter_1_regex, names_string)[1]\n",
    "        fighter_1 = fighter_1.replace(fighter_2_replace, \"\")[:-1]\n",
    "    # Getting fighter odds\n",
    "    ml_string = row['Unnamed: 3']\n",
    "    if len(ml_string) == 8:\n",
    "        ml_fighter_2 = ml_string[:4]\n",
    "        ml_fighter_1 = ml_string[-4:]\n",
    "    elif len(ml_string) == 9:\n",
    "        if (ml_string[4] == '+') | (ml_string[4]=='-'):\n",
    "            ml_fighter_2 = ml_string[:4]\n",
    "            ml_fighter_1 = ml_string[-5:]\n",
    "        else:\n",
    "            ml_fighter_2 = ml_string[:5]\n",
    "            ml_fighter_1 = ml_string[-4:]\n",
    "    elif len(ml_string) == 10:\n",
    "            ml_fighter_2 = ml_string[:5]\n",
    "            ml_fighter_1 = ml_string[-5:]\n",
    "    else:\n",
    "        continue\n",
    "    try:\n",
    "        ml_fighter_2 = float(ml_fighter_2)\n",
    "    except:\n",
    "        continue\n",
    "    try:\n",
    "        ml_fighter_1 = float(ml_fighter_1)\n",
    "    except:\n",
    "        continue\n",
    "    # Adding data to odds df\n",
    "    new_data = [fighter_1, fighter_2, ml_fighter_1, ml_fighter_2]\n",
    "    new_df = pd.DataFrame([new_data])\n",
    "    new_df.columns = odds_df.columns\n",
    "    odds_df = pd.concat([odds_df, new_df], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_8481/2576513570.py:20: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_8481/2576513570.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_8481/2576513570.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_8481/2576513570.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_8481/2576513570.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_8481/2576513570.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_8481/2576513570.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_8481/2576513570.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_8481/2576513570.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_8481/2576513570.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_8481/2576513570.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_8481/2576513570.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_8481/2576513570.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_8481/2576513570.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_8481/2576513570.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_8481/2576513570.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_8481/2576513570.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_8481/2576513570.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_8481/3744728841.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Appending this week's fight data to existing dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mthis_weeks_fights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretrieve_this_weeks_fights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Training models & using it to predict fights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mthis_weeks_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthis_weeks_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_weeks_fights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_8481/2576513570.py\u001b[0m in \u001b[0;36mretrieve_this_weeks_fights\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'span'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'b-content__title-highlight'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregex_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprettify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'l'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mreach\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregex_reach\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprettify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mdob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregex_dob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprettify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Appending this week's fight data to existing dataset\n",
    "this_weeks_fights = retrieve_this_weeks_fights()\n",
    "\n",
    "# Training models & using it to predict fights\n",
    "this_weeks_predictions = this_weeks_predictions(this_weeks_fights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
