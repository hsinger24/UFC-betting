{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "162801b9",
   "metadata": {},
   "source": [
    "# Setting Up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95a58620",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Imports \n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fb32402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions \n",
    "\n",
    "def calculate_odds(odds):\n",
    "    if odds<0:\n",
    "        return (abs(odds)/(abs(odds)+100))\n",
    "    if odds>0:\n",
    "        return (100/(odds+100))\n",
    "\n",
    "def calculate_bets_gb(row, diff):\n",
    "    bet = 0\n",
    "    fighter = ''\n",
    "    if (row.Prediction_GB_Winner != 0):\n",
    "        if row.Prediction_GB_Winner - calculate_odds(row.Fighter_1_Odds) >= diff:\n",
    "            bet = 100\n",
    "            fighter = row.Fighter_1\n",
    "        if (1.0 - row.Prediction_GB_Winner) - calculate_odds(row.Fighter_2_Odds) >= diff:\n",
    "            bet = 100\n",
    "            fighter = row.Fighter_2\n",
    "    if bet > 0:\n",
    "        rec = f'Bet 100 on {fighter}'\n",
    "    else:\n",
    "        rec = 'No bet'\n",
    "    return rec\n",
    "\n",
    "def calculate_bets_lgbm(row):\n",
    "    bet = 0\n",
    "    if (row.Prediction_LGBM_Winner != 0):\n",
    "        if row.Prediction_LGBM_Winner > 0.5:\n",
    "            bet = 100\n",
    "            fighter = row.Fighter_1\n",
    "        else:\n",
    "            bet = 100\n",
    "            fighter = row.Fighter_2\n",
    "    if bet > 0:\n",
    "        rec = f'Bet 100 on {fighter}'\n",
    "    else:\n",
    "        rec = 'No bet'\n",
    "    return rec\n",
    "\n",
    "def ml_data_prep(target):\n",
    "\n",
    "    # Importing data to train RF\n",
    "    data = pd.read_csv('mma_data.csv', index_col=0)\n",
    "\n",
    "    # Filtering out unwanted rows\n",
    "    data = data[data.slpm_2 + data.sapm_2 != 0]\n",
    "    data = data[data.slpm_1 + data.sapm_1 != 0]\n",
    "    data = data[data.result >= 0]\n",
    "\n",
    "    # Engineering some columns\n",
    "    data['strike_diff_1'] = data.slpm_1 - data.sapm_1\n",
    "    data['strike_diff_2'] = data.slpm_2 - data.sapm_2\n",
    "    data['strike_diff'] = data.strike_diff_1 - data.strike_diff_2\n",
    "    data['td_diff_1'] = data.td_acc_1 - data.td_def_1\n",
    "    data['td_diff_2'] = data.td_acc_2 - data.td_def_2\n",
    "    data['td_diff'] = data.td_diff_1 - data.td_diff_2\n",
    "    data['reach_diff'] = data.reach_1 - data.reach_2\n",
    "    data['age_diff'] = data.age_1 - data.age_2\n",
    "    data['slpm_diff'] = data.slpm_1 - data.slpm_2\n",
    "    data['sapm_diff'] = data.sapm_1 - data.sapm_2\n",
    "    data['td_acc_diff'] = data.td_acc_1 - data.td_acc_2\n",
    "    data['td_def_diff'] = data.td_def_1 - data.td_def_2\n",
    "    data['td_avg_diff'] = data.td_avg_1 - data.td_avg_2\n",
    "    data['sub_avg_diff'] = data.sub_avg_1 - data.sub_avg_2\n",
    "    data['strk_acc_diff'] = data.strk_acc_1 - data.strk_acc_2\n",
    "    data['strk_def_diff'] = data.strk_def_1 - data.strk_def_2\n",
    "    data['wins_diff'] = data.wins_1 - data.wins_2\n",
    "    data['losses_diff'] = data.losses_1 - data.losses_2\n",
    "    data['win_pct_1'] = data.wins_1/(data.losses_1 + data.wins_1)\n",
    "    data['win_pct_2'] = data.wins_2/(data.losses_2 + data.wins_2)\n",
    "    data['win_pct_diff'] = data.win_pct_1 - data.win_pct_2\n",
    "\n",
    "    # Droping unecessary columnns and scaling data\n",
    "    x_cols = ['reach_diff', 'age_diff', 'slpm_diff', 'sapm_diff', 'td_acc_diff', 'td_def_diff',\n",
    "                'td_avg_diff', 'sub_avg_diff', 'strk_acc_diff', 'strk_def_diff', 'wins_diff',\n",
    "                'losses_diff', 'win_pct_diff', 'weight_1', 'age_1', 'strike_diff', 'td_diff']\n",
    "    y_col = target\n",
    "\n",
    "    x, y = data[x_cols], data[y_col]\n",
    "    y = y.values.ravel()\n",
    "\n",
    "    return x, y, x_cols\n",
    "\n",
    "def create_grid_search(model, param_grid, x, y, cv = 10):\n",
    "    # Running Grid Search\n",
    "    grid_search = GridSearchCV(model, param_grid, cv = cv)\n",
    "    grid_search.fit(x, y)\n",
    "    \n",
    "    # Outputting results\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e141077",
   "metadata": {},
   "source": [
    "# Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c19cab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling odds\n",
    "\n",
    "# Adding new fights to odds data\n",
    "data_filled = pd.read_csv('mma_data_odds.csv', index_col = 0)\n",
    "data_all = pd.read_csv('mma_data.csv', index_col = 0)\n",
    "data_all = data_all[data_all.result >= 0]\n",
    "data_all['Fighter_1_Odds'] = 0\n",
    "data_all['Fighter_2_Odds'] = 0\n",
    "# Filling odds w/ data with recent fights\n",
    "last_row_filled = data_filled.tail(1)\n",
    "fighter_1_last = last_row_filled.fighter_1.values[0]\n",
    "fighter_2_last = last_row_filled.fighter_2.values[0]\n",
    "data_all_copied = data_all.copy()\n",
    "data_all_copied.reset_index(inplace = True, drop = True)\n",
    "cutoff_unfilled = data_all_copied[(data_all_copied.fighter_1 == fighter_1_last) & \n",
    "                                (data_all_copied.fighter_2 == fighter_2_last)].index[0]\n",
    "data_all_new = data_all_copied.iloc[cutoff_unfilled+1:]\n",
    "data = pd.concat([data_filled, data_all_new])\n",
    "\n",
    "# Filling in odds\n",
    "driver = webdriver.Safari()\n",
    "driver.get('https://www.bestfightodds.com/archive')\n",
    "time.sleep(1)\n",
    "for index, row in data.iterrows():\n",
    "    try:\n",
    "        if row.Fighter_1_Odds == 0:\n",
    "            # Formatting name of higher ranked fighter\n",
    "            fighter_1 = str(row.fighter_1)\n",
    "            fighter_1 = re.findall('[A-Z][^A-Z]*', fighter_1)    \n",
    "            fighter_name = ''\n",
    "            for name in fighter_1:\n",
    "                fighter_name = fighter_name + ' ' + name\n",
    "            # Formatting name of lower ranked fighter\n",
    "            fighter_2 = str(row.fighter_2)\n",
    "            fighter_2 = re.findall('[A-Z][^A-Z]*', fighter_2)    \n",
    "            fighter_name_2 = ''\n",
    "            for name in fighter_2:\n",
    "                fighter_name_2 = fighter_name_2 + ' ' + name\n",
    "            # Searching for fights w/ higher ranked fighter\n",
    "            search_bar = driver.find_elements(By.XPATH, '//*[@id=\"page-content\"]/form/p/input[1]')[0]\n",
    "            search_bar.send_keys(fighter_name)\n",
    "            driver.find_elements(By.XPATH, '//*[@id=\"page-content\"]/form/p/input[2]')[0].click()\n",
    "            time.sleep(1)\n",
    "            # Clicking on fighter 1 \n",
    "            try:\n",
    "                click_button = WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"page-content\"]/table[1]/tbody/tr[1]/td[2]/a')))\n",
    "                driver.find_elements(By.XPATH, '//*[@id=\"page-content\"]/table[1]/tbody/tr[1]/td[2]/a')[0].click()\n",
    "                time.sleep(1)\n",
    "            except:\n",
    "                pass\n",
    "            # Getting odds\n",
    "            html = driver.page_source\n",
    "            table = pd.read_html(html)[0]\n",
    "            table = table[['Matchup', 'Closing range']]\n",
    "            table['Fuzzy_1'] = table.Matchup.apply(lambda x: fuzz.ratio(x, fighter_name))\n",
    "            table['Fuzzy_2'] = table.Matchup.apply(lambda x: fuzz.ratio(x, fighter_name_2))\n",
    "            table = table[(table.Fuzzy_2 > 50) | (table.Fuzzy_1 > 50)].reset_index(drop = True)\n",
    "            index_opp = table[table.Fuzzy_2 > 50].index[0]\n",
    "            table_matchup = table.loc[index_opp-1:index_opp, :].reset_index(drop = True)\n",
    "            # Filling odds\n",
    "            data.loc[index, 'Fighter_1_Odds'] = table_matchup.loc[0, 'Closing range']\n",
    "            data.loc[index, 'Fighter_2_Odds'] = table_matchup.loc[1, 'Closing range']\n",
    "            # Navigating back and clearing text box\n",
    "            driver.back()\n",
    "            driver.implicitly_wait(10)\n",
    "            driver.back()\n",
    "            driver.implicitly_wait(10)\n",
    "            driver.find_elements(By.XPATH, '//*[@id=\"page-content\"]/form/p/input[1]')[0].clear()\n",
    "        else:\n",
    "            pass\n",
    "    except:\n",
    "        driver.quit()\n",
    "        time.sleep(1)\n",
    "        driver = webdriver.Safari()\n",
    "        driver.get('https://www.bestfightodds.com/archive')\n",
    "data = data[(data.Fighter_1_Odds != 0) & (data.Fighter_2_Odds != 0)]\n",
    "data.dropna(subset = ['Fighter_1_Odds', 'Fighter_2_Odds'], inplace = True)\n",
    "data.reset_index(inplace = True, drop = True)\n",
    "\n",
    "# Saving updated file\n",
    "data.to_csv('mma_data_odds.csv')\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7e4296e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB - With a cutoff of 0.05, betting results are 323.3091833123599\n",
      "GB - With a cutoff of 0.1, betting results are 188.29681461537297\n",
      "GB - With a cutoff of 0.15, betting results are -383.70446529450624\n",
      "GB - With a cutoff of 0.2, betting results are -625.0125769797901\n",
      "GB - With a cutoff of 0.25, betting results are -131.78506375227687\n",
      "GB - With a cutoff of 0.3, betting results are -25.0\n",
      "GB - With a cutoff of 0.35, betting results are 0\n",
      "GB - With a cutoff of 0.4, betting results are 0\n",
      "GB - With a cutoff of 0.45, betting results are 0\n",
      "GB - With a cutoff of 0.5, betting results are 0\n",
      "GB - For a 0 fight minimum, the model returns 323.3091833123599\n",
      "GB - For a 5 fight minimum, the model returns 323.3091833123599\n",
      "GB - For a 10 fight minimum, the model returns 151.44643821432052\n",
      "GB - For a 15 fight minimum, the model returns 125.86315278550671\n",
      "GB - For a 20 fight minimum, the model returns 63.15330280917749\n",
      "GB - For a 25 fight minimum, the model returns -556.1566917930916\n"
     ]
    }
   ],
   "source": [
    "# Calculating best GB bet construct\n",
    "\n",
    "# Internal functions\n",
    "\n",
    "def calculate_odds_internal(odds):\n",
    "    if odds<0:\n",
    "        return (abs(odds)/(abs(odds)+100))\n",
    "    if odds>0:\n",
    "        return (100/(odds+100))\n",
    "def calculate_bets_internal(row, diff):\n",
    "    bet = 0\n",
    "    if row.Prediction_GB_Winner - calculate_odds_internal(row.Fighter_1_Odds) >= diff:\n",
    "        bet = 100\n",
    "    if (1.0 - row.Prediction_GB_Winner) - calculate_odds_internal(row.Fighter_2_Odds) >= diff:\n",
    "        bet = 100\n",
    "    return bet\n",
    "def calculate_payoff_and_result_internal(row):\n",
    "    if row.Bet > 0:\n",
    "        # Calculating Payoff\n",
    "        if row.Predicted_Result_GB == 1:\n",
    "            if row.Fighter_1_Odds>0:\n",
    "                payoff = (row.Fighter_1_Odds/100)*row.Bet\n",
    "            else:\n",
    "                payoff = row.Bet/((abs(row.Fighter_1_Odds)/100))\n",
    "        else:\n",
    "            if row.Fighter_2_Odds>0:\n",
    "                payoff = (row.Fighter_2_Odds/100)*row.Bet\n",
    "            else:\n",
    "                payoff = row.Bet/((abs(row.Fighter_2_Odds)/100))\n",
    "        # Calculating Bet Result\n",
    "        if row.Predicted_Result_GB == row.result_y:\n",
    "            bet_result = payoff\n",
    "        else:\n",
    "            bet_result = -(row.Bet)\n",
    "    else:\n",
    "        bet_result = 0\n",
    "    return bet_result\n",
    "        \n",
    "# Joining predictions to table w/ results and getting result\n",
    "predictions = pd.read_csv('mma_data_predictions.csv', index_col = 0)\n",
    "data = pd.read_csv('mma_data.csv', index_col = 0)\n",
    "data = data[data.result >= 0]\n",
    "results_data = data[['fighter_1', 'fighter_2', 'result', 'KO_OVR', 'SUB_OVR']]\n",
    "odds_data = pd.read_csv('mma_data_odds.csv', index_col = 0)\n",
    "merged = predictions.merge(results_data, on = ['fighter_1', 'fighter_2'])\n",
    "# Winner results\n",
    "merged['Predicted_Result_RF'] = merged.Prediction_RF_Winner.apply(lambda x: 1 if x > 0.5 else 0)\n",
    "merged['Predicted_Result_GB'] = merged.Prediction_GB_Winner.apply(lambda x: 1 if x > 0.5 else 0)\n",
    "# merged['Accurate_RF'] = merged.apply(lambda x: 1 if x.result_y == x.Predicted_Result_RF else 0, axis = 1)\n",
    "# merged['Accurate_GB'] = merged.apply(lambda x: 1 if x.result_y == x.Predicted_Result_GB else 0, axis = 1)\n",
    "# # Sub results\n",
    "# merged['Predicted_Sub_RF'] = merged.Prediction_RF_SUB.apply(lambda x: 1 if x > 0.5 else 0)\n",
    "# merged['Predicted_Sub_GB'] = merged.Prediction_GB_SUB.apply(lambda x: 1 if x > 0.5 else 0)\n",
    "# merged['Accurate_RF_SUB'] = merged.apply(lambda x: 1 if x.SUB_OVR_y == x.Predicted_Sub_RF else 0, axis = 1)\n",
    "# merged['Accurate_GB_SUB'] = merged.apply(lambda x: 1 if x.SUB_OVR_y == x.Predicted_Sub_GB else 0, axis = 1)\n",
    "# # KO Results\n",
    "# merged['Predicted_KO_RF'] = merged.Prediction_RF_KO.apply(lambda x: 1 if x > 0.5 else 0)\n",
    "# merged['Predicted_KO_GB'] = merged.Prediction_GB_KO.apply(lambda x: 1 if x > 0.5 else 0)\n",
    "# merged['Accurate_RF_KO'] = merged.apply(lambda x: 1 if x.KO_OVR_y == x.Predicted_KO_RF else 0, axis = 1)\n",
    "# merged['Accurate_GB_KO'] = merged.apply(lambda x: 1 if x.KO_OVR_y == x.Predicted_KO_GB else 0, axis = 1)\n",
    "# Getting all the relevant data in one place for bet constructs\n",
    "odds_data = odds_data[['fighter_1', 'fighter_2', 'Fighter_1_Odds', 'Fighter_2_Odds']]\n",
    "profit_df = merged.merge(odds_data, on = ['fighter_1', 'fighter_2'])\n",
    "profit_df = profit_df[(profit_df.Fighter_1_Odds!=0) & (profit_df.Fighter_2_Odds!=0)]\n",
    "\n",
    "# Determining best bet construct\n",
    "\n",
    "best_diff = 0\n",
    "best_profit = 0\n",
    "best_fight_number = 0\n",
    "for i in [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]:\n",
    "    profit_df['Bet'] = profit_df.apply(calculate_bets_internal, diff = i, axis = 1)\n",
    "    profit_df['Bet_Result'] = profit_df.apply(calculate_payoff_and_result_internal, axis = 1)\n",
    "    print(f'GB - With a cutoff of {i}, betting results are {profit_df.Bet_Result.sum()}')\n",
    "    if float(profit_df.Bet_Result.sum()) > best_profit:\n",
    "        best_diff = i\n",
    "    if profit_df.Bet_Result.sum() > best_profit:\n",
    "        best_profit = profit_df.Bet_Result.sum()\n",
    "# Veteran fights only\n",
    "best_profit = 0\n",
    "profit_df['Bet'] = profit_df.apply(calculate_bets_internal, diff = best_diff, axis = 1)\n",
    "profit_df['Bet_Result'] = profit_df.apply(calculate_payoff_and_result_internal, axis = 1)\n",
    "for num_fights in [0, 5, 10, 15, 20, 25]:\n",
    "    profit_df['Fights_1'] = profit_df.wins_1 + profit_df.losses_1\n",
    "    profit_df['Fights_2'] = profit_df.wins_2 + profit_df.losses_2\n",
    "    test = profit_df[(profit_df.Fights_1 > num_fights) | (profit_df.Fights_2 > num_fights)]\n",
    "    results = test.Bet_Result.sum()\n",
    "    print(f'GB - For a {num_fights} fight minimum, the model returns {results}')\n",
    "    if results > best_profit:\n",
    "        best_fight_number = num_fights\n",
    "    if results > best_profit:\n",
    "        best_profit = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18b6536d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM - For a 10 minimum, the model returns 397.9926595386885\n",
      "LGBM - For a 15 minimum, the model returns 759.3129825237804\n",
      "LGBM - For a 20 minimum, the model returns 1251.5940411710048\n",
      "LGBM - For a 25 minimum, the model returns 595.0450703967624\n"
     ]
    }
   ],
   "source": [
    "# Calculating best LGBM bet construct\n",
    "\n",
    "# Calculating straight bet results\n",
    "def calculate_straight_internal(row):\n",
    "    # Calculating Payoff\n",
    "    if row.Predicted_Result_LGBM == 1:\n",
    "        if row.Fighter_1_Odds>0:\n",
    "            payoff = (row.Fighter_1_Odds/100)*row.Bet\n",
    "        else:\n",
    "            payoff = row.Bet/((abs(row.Fighter_1_Odds)/100))\n",
    "    else:\n",
    "        if row.Fighter_2_Odds>0:\n",
    "            payoff = (row.Fighter_2_Odds/100)*row.Bet\n",
    "        else:\n",
    "            payoff = row.Bet/((abs(row.Fighter_2_Odds)/100))\n",
    "    # Calculating Bet Result\n",
    "    if row.Predicted_Result_LGBM == row.result_y:\n",
    "        bet_result = payoff\n",
    "    else:\n",
    "        bet_result = -(row.Bet)\n",
    "\n",
    "    return bet_result\n",
    "\n",
    "# Joining predictions to table w/ results and getting result\n",
    "predictions = pd.read_csv('mma_data_predictions.csv', index_col = 0)\n",
    "data = pd.read_csv('mma_data.csv', index_col = 0)\n",
    "data = data[data.result >= 0]\n",
    "results_data = data[['fighter_1', 'fighter_2', 'result', 'KO_OVR', 'SUB_OVR']]\n",
    "odds_data = pd.read_csv('mma_data_odds.csv', index_col = 0)\n",
    "merged = predictions.merge(results_data, on = ['fighter_1', 'fighter_2'])\n",
    "# Winner results\n",
    "merged['Predicted_Result_RF'] = merged.Prediction_RF_Winner.apply(lambda x: 1 if x > 0.5 else 0)\n",
    "merged['Predicted_Result_GB'] = merged.Prediction_GB_Winner.apply(lambda x: 1 if x > 0.5 else 0)\n",
    "merged['Predicted_Result_LGBM'] = merged.Prediction_LGBM_Winner.apply(lambda x: 1 if x > 0.5 else 0)\n",
    "# Joining to odds df\n",
    "odds_data = odds_data[['fighter_1', 'fighter_2', 'Fighter_1_Odds', 'Fighter_2_Odds']]\n",
    "profit_df = merged.merge(odds_data, on = ['fighter_1', 'fighter_2'])\n",
    "profit_df = profit_df[(profit_df.Fighter_1_Odds!=0) & (profit_df.Fighter_2_Odds!=0)]\n",
    "# Calculating results\n",
    "profit_df['Bet'] = 100\n",
    "profit_df['Bet_Result'] = profit_df.apply(calculate_straight_internal, axis = 1)\n",
    "\n",
    "# Determining best bet construct\n",
    "\n",
    "best_profit = 0\n",
    "best_fight_number = 0\n",
    "for num_fights in [10, 15, 20, 25]:\n",
    "    profit_df['Fights_1'] = profit_df.wins_1 + profit_df.losses_1\n",
    "    profit_df['Fights_2'] = profit_df.wins_2 + profit_df.losses_2\n",
    "    test = profit_df[(profit_df.Fights_1 > num_fights) | (profit_df.Fights_2 > num_fights)]\n",
    "    results = test.Bet_Result.sum()\n",
    "    print(f'LGBM - For a {num_fights} minimum, the model returns {results}')\n",
    "    if float(profit_df.Bet_Result.sum()) > best_profit:\n",
    "        best_fight_number_lgbm = num_fights\n",
    "    if profit_df.Bet_Result.sum() > best_profit:\n",
    "        best_profit = profit_df.Bet_Result.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9848c6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_39557/2024439342.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_39557/2024439342.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_39557/2024439342.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_39557/2024439342.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_39557/2024439342.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_39557/2024439342.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_39557/2024439342.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_39557/2024439342.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_39557/2024439342.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_39557/2024439342.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_39557/2024439342.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_39557/2024439342.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_39557/2024439342.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_39557/2024439342.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_39557/2024439342.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_39557/2024439342.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_39557/2024439342.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_39557/2024439342.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_39557/2024439342.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_39557/2024439342.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_39557/2024439342.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_39557/2024439342.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_39557/2024439342.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_39557/2024439342.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_39557/2024439342.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_39557/2024439342.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "# Retrieving this weeks fights\n",
    "\n",
    "# Instantating constants\n",
    "\n",
    "regex_weight = r\"\\d{3}\\sl\"\n",
    "regex_reach = r'\\d{2}\"'\n",
    "regex_dob = r',\\s\\d{4}'\n",
    "regex_various_stats = r'\\d{1}\\.\\d{1,2}'\n",
    "regex_various_stats_2 = r'\\d{1,2}%'\n",
    "regex_record = r'\\d{1,2}-\\d{1,2}-\\d{1,2}'\n",
    "year = dt.date.today().year\n",
    "fight_data = pd.DataFrame()\n",
    "options = Options()\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument(\"user-data-dir=/Users/hsinger24/Library/Application Support/Google/Chrome/Default1\")\n",
    "options.add_argument(\"--start-maximized\")\n",
    "options.add_argument('--disable-web-security')\n",
    "options.add_argument('--allow-running-insecure-content')\n",
    "options.add_argument(\"--disable-setuid-sandbox\")\n",
    "driver = webdriver.Safari()\n",
    "driver.get('http://ufcstats.com/statistics/events/completed')\n",
    "# driver.maximize_window()\n",
    "upcoming_card_data = pd.DataFrame(columns = ['name', 'weight', 'reach', 'age', 'slpm', 'sapm', 'td_avg', 'sub_avg', 'strk_acc', 'strk_def', 'td_acc',\n",
    "                                            'td_def', 'wins', 'losses'])\n",
    "\n",
    "# Getting data for upcoming card\n",
    "\n",
    "links_home_page = driver.find_elements(By.TAG_NAME, 'a') \n",
    "del links_home_page[:6] \n",
    "upcoming_card = links_home_page[0] \n",
    "upcoming_card.click() \n",
    "time.sleep(2)\n",
    "links_upcoming_card = driver.find_elements(By.TAG_NAME, 'a') \n",
    "del links_upcoming_card[:4]\n",
    "for i in range(7):\n",
    "    del links_upcoming_card[-1]\n",
    "for i, link in enumerate(links_upcoming_card):\n",
    "    if link.text in ['View\\nMatchup', 'View Matchup  ']:\n",
    "        del links_upcoming_card[i]\n",
    "num_fighters = len(links_upcoming_card)\n",
    "fighter = links_upcoming_card[0]\n",
    "fighter.click()\n",
    "for i in range(num_fighters):\n",
    "    if i!=0:\n",
    "        links_upcoming_card = driver.find_elements(By.TAG_NAME, 'a')\n",
    "        del links_upcoming_card[:4]\n",
    "        for j, link in enumerate(links_upcoming_card):\n",
    "            if link.text in ['View\\nMatchup', 'View Matchup  ']:\n",
    "                del links_upcoming_card[j]\n",
    "        fighter= links_upcoming_card[i]\n",
    "        fighter.click() \n",
    "    time.sleep(2)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    name = soup.find_all('span', class_ = 'b-content__title-highlight')[0].text.replace('\\n', '').replace(' ', '')\n",
    "    try:\n",
    "        weight = float(re.findall(regex_weight, soup.prettify())[0].strip('l').replace(' ', ''))\n",
    "        reach = float(re.findall(regex_reach, soup.prettify())[1].strip('\"'))\n",
    "    except:\n",
    "        weight = 0\n",
    "        reach = 0\n",
    "    dob = int(re.findall(regex_dob, soup.prettify())[0].strip(',').replace(' ', ''))\n",
    "    age = year - dob\n",
    "    slpm = float(re.findall(regex_various_stats, soup.prettify())[1])\n",
    "    sapm = float(re.findall(regex_various_stats, soup.prettify())[2])\n",
    "    td_avg = float(re.findall(regex_various_stats, soup.prettify())[3])\n",
    "    sub_avg = float(re.findall(regex_various_stats, soup.prettify())[4])\n",
    "    strk_acc = float(re.findall(regex_various_stats_2, soup.prettify())[0].strip('%'))\n",
    "    strk_def = float(re.findall(regex_various_stats_2, soup.prettify())[1].strip('%'))\n",
    "    td_acc = float(re.findall(regex_various_stats_2, soup.prettify())[2].strip('%'))\n",
    "    td_def = float(re.findall(regex_various_stats_2, soup.prettify())[3].strip('%'))\n",
    "    record = re.findall(regex_record, soup.prettify())[0]\n",
    "    record = record.split('-')\n",
    "    wins = float(record[0])\n",
    "    losses = float(record[1])\n",
    "    list_of_stats = [name, weight, reach, age, slpm, sapm, td_avg, sub_avg, strk_acc, strk_def, td_acc, td_def, wins, losses]\n",
    "    series = pd.Series(list_of_stats, index = upcoming_card_data.columns)\n",
    "    upcoming_card_data = upcoming_card_data.append(series, ignore_index = True)\n",
    "    driver.back()\n",
    "evens = upcoming_card_data.iloc[::2]\n",
    "evens.reset_index(drop = True, inplace = True)\n",
    "odds = upcoming_card_data.iloc[1::2]\n",
    "odds.reset_index(drop = True, inplace = True)\n",
    "final= pd.merge(evens, odds, left_index = True, right_index = True)\n",
    "final.columns = ['fighter_1', 'weight_1', 'reach_1', 'age_1', 'slpm_1', 'sapm_1', 'td_avg_1', 'sub_avg_1', \n",
    "                'strk_acc_1', 'strk_def_1', 'td_acc_1','td_def_1', 'wins_1', 'losses_1', 'fighter_2', 'weight_2', \n",
    "                'reach_2', 'age_2', 'slpm_2', 'sapm_2', 'td_avg_2', 'sub_avg_2', 'strk_acc_2', 'strk_def_2', \n",
    "                'td_acc_2','td_def_2', 'wins_2', 'losses_2']\n",
    "final['result'] = -5\n",
    "final['SUB_OVR']= 0\n",
    "final['KO_OVR'] = 0\n",
    "final = final[(final.weight_1 != 0) & (final.weight_2 != 0)]\n",
    "\n",
    "this_weeks_fights = final.copy()\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cae927ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_39557/1527190485.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  mma_data = mma_data.append(this_weeks_fights)\n"
     ]
    }
   ],
   "source": [
    "# Appending this weeks fights\n",
    "\n",
    "mma_data = pd.read_csv('mma_data.csv', index_col = 0)\n",
    "mma_data = mma_data.append(this_weeks_fights)\n",
    "mma_data.reset_index(inplace = True, drop = True)\n",
    "mma_data.to_csv('mma_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a074f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions for this weeks fights\n",
    "\n",
    "# Getting x and y for models\n",
    "x, y, x_cols = ml_data_prep(target = 'result')\n",
    "x_scaled = StandardScaler().fit_transform(x)\n",
    "# x_ko, y_ko, x_cols = ml_data_prep(target = 'KO_OVR')\n",
    "# x_ko_scaled = StandardScaler().fit_transform(x_ko)\n",
    "# x_sub, y_sub, x_cols = ml_data_prep(target = 'SUB_OVR')\n",
    "# x_sub_scaled = StandardScaler().fit_transform(x_sub)\n",
    "\n",
    "# Prep grid searches\n",
    "# RF\n",
    "n_estimators = [int(x) for x in np.linspace(start = 3, stop = 15, num = 13)]\n",
    "max_features = [int(x) for x in np.linspace(start = 3, stop = 10, num = 8)]\n",
    "max_depth = [int(x) for x in np.linspace(start = 1, stop = 10, num = 10)]\n",
    "param_grid_rf = {\n",
    "    'n_estimators' : n_estimators,\n",
    "    'max_features' : max_features,\n",
    "    'max_depth' : max_depth\n",
    "}\n",
    "# GB\n",
    "n_estimators = [int(x) for x in np.linspace(start = 3, stop = 15, num = 13)]\n",
    "max_features = [int(x) for x in np.linspace(start = 3, stop = 10, num = 8)]\n",
    "max_depth = [int(x) for x in np.linspace(start = 1, stop = 10, num = 10)]\n",
    "param_grid_gb = {\n",
    "    'n_estimators' : n_estimators,\n",
    "    'max_features' : max_features,\n",
    "    'max_depth' : max_depth\n",
    "}\n",
    "# LR\n",
    "c = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "param_grid_lr = {\n",
    "    'C' : c\n",
    "}\n",
    "# LGBM\n",
    "max_iter = [int(x) for x in np.linspace(start = 5, stop = 15, num = 11)]\n",
    "max_leaf_nodes = [int(x) for x in np.linspace(start = 4, stop = 10, num = 7)]\n",
    "max_depth = [int(x) for x in np.linspace(start = 4, stop = 10, num = 7)]\n",
    "learning_rate = [0.001, 0.01, 0.1, 1]\n",
    "param_grid_lgbm = {\n",
    "    'max_iter' : max_iter,\n",
    "    'max_leaf_nodes' : max_leaf_nodes,\n",
    "    'max_depth' : max_depth,\n",
    "    'learning_rate' : learning_rate\n",
    "}\n",
    "\n",
    "# Saving best winner models from grid searches\n",
    "rf_winner = create_grid_search(RandomForestClassifier(random_state = 0, class_weight = 'balanced'), param_grid_rf, cv = 10, x = x, y = y)\n",
    "gb_winner = create_grid_search(GradientBoostingClassifier(random_state = 0), param_grid_gb, cv = 10, x = x, y = y)\n",
    "lgbm_winner = create_grid_search(HistGradientBoostingClassifier(random_state = 0), param_grid_lgbm, cv = 10, x = x, y = y)\n",
    "# lr_winner = create_grid_search(LogisticRegression(random_state = 0, class_weight = 'balanced', max_iter = 500), param_grid_lr, cv = 10, x = x_scaled, y = y)\n",
    "# rf_ko = create_grid_search(RandomForestClassifier(random_state = 0, class_weight = 'balanced'), param_grid_rf, cv = 10, x = x_ko, y = y_ko)\n",
    "# gb_ko = create_grid_search(GradientBoostingClassifier(random_state = 0), param_grid_gb, cv = 10, x = x_ko, y = y_ko)\n",
    "# lr_ko = create_grid_search(LogisticRegression(random_state = 0, class_weight = 'balanced', max_iter = 500), param_grid_lr, cv = 10, x = x_ko_scaled, y = y_ko)\n",
    "# rf_sub = create_grid_search(RandomForestClassifier(random_state = 0, class_weight = 'balanced'), param_grid_rf, cv = 10, x = x_sub, y = y_sub)\n",
    "# gb_sub = create_grid_search(GradientBoostingClassifier(random_state = 0), param_grid_gb, cv = 10, x = x_sub, y = y_sub)\n",
    "# lr_sub = create_grid_search(LogisticRegression(random_state = 0, class_weight = 'balanced', max_iter = 500), param_grid_lr, cv = 10, x = x_sub_scaled, y = y_sub)\n",
    "\n",
    "# Filtering out fights with UFC newcomers\n",
    "this_weeks_fights = this_weeks_fights[this_weeks_fights.slpm_2 + this_weeks_fights.sapm_2 != 0]\n",
    "this_weeks_fights = this_weeks_fights[this_weeks_fights.slpm_1 + this_weeks_fights.sapm_1 != 0]\n",
    "\n",
    "# Preparing prediction data & predicting\n",
    "this_weeks_fights['strike_diff_1'] = this_weeks_fights.slpm_1 - this_weeks_fights.sapm_1\n",
    "this_weeks_fights['strike_diff_2'] = this_weeks_fights.slpm_2 - this_weeks_fights.sapm_2\n",
    "this_weeks_fights['strike_diff'] = this_weeks_fights.strike_diff_1 - this_weeks_fights.strike_diff_2\n",
    "this_weeks_fights['td_diff_1'] = this_weeks_fights.td_acc_1 - this_weeks_fights.td_def_1\n",
    "this_weeks_fights['td_diff_2'] = this_weeks_fights.td_acc_2 - this_weeks_fights.td_def_2\n",
    "this_weeks_fights['td_diff'] = this_weeks_fights.td_diff_1 - this_weeks_fights.td_diff_2\n",
    "this_weeks_fights['reach_diff'] = this_weeks_fights.reach_1 - this_weeks_fights.reach_2\n",
    "this_weeks_fights['age_diff'] = this_weeks_fights.age_1 - this_weeks_fights.age_2\n",
    "this_weeks_fights['slpm_diff'] = this_weeks_fights.slpm_1 - this_weeks_fights.slpm_2\n",
    "this_weeks_fights['sapm_diff'] = this_weeks_fights.sapm_1 - this_weeks_fights.sapm_2\n",
    "this_weeks_fights['td_acc_diff'] = this_weeks_fights.td_acc_1 - this_weeks_fights.td_acc_2\n",
    "this_weeks_fights['td_def_diff'] = this_weeks_fights.td_def_1 - this_weeks_fights.td_def_2\n",
    "this_weeks_fights['td_avg_diff'] = this_weeks_fights.td_avg_1 - this_weeks_fights.td_avg_2\n",
    "this_weeks_fights['sub_avg_diff'] = this_weeks_fights.sub_avg_1 - this_weeks_fights.sub_avg_2\n",
    "this_weeks_fights['strk_acc_diff'] = this_weeks_fights.strk_acc_1 - this_weeks_fights.strk_acc_2\n",
    "this_weeks_fights['strk_def_diff'] = this_weeks_fights.strk_def_1 - this_weeks_fights.strk_def_2\n",
    "this_weeks_fights['wins_diff'] = this_weeks_fights.wins_1 - this_weeks_fights.wins_2\n",
    "this_weeks_fights['losses_diff'] = this_weeks_fights.losses_1 - this_weeks_fights.losses_2\n",
    "this_weeks_fights['win_pct_1'] = this_weeks_fights.wins_1/(this_weeks_fights.losses_1 + this_weeks_fights.wins_1)\n",
    "this_weeks_fights['win_pct_2'] = this_weeks_fights.wins_2/(this_weeks_fights.losses_2 + this_weeks_fights.wins_2)\n",
    "this_weeks_fights['win_pct_diff'] = this_weeks_fights.win_pct_1 - this_weeks_fights.win_pct_2\n",
    "\n",
    "x_data_pred = this_weeks_fights[x_cols]\n",
    "\n",
    "this_weeks_fights['Prediction_RF_Winner'] = rf_winner.predict_proba(x_data_pred)[:, 1]\n",
    "this_weeks_fights['Prediction_GB_Winner'] = gb_winner.predict_proba(x_data_pred)[:, 1]\n",
    "this_weeks_fights['Prediction_LGBM_Winner'] = lgbm_winner.predict_proba(x_data_pred)[:, 1]\n",
    "# this_weeks_fights['Prediction_LR_Winner'] = lr_winner.predict_proba(x_data_pred)[:, 1]\n",
    "# this_weeks_fights['Prediction_RF_SUB'] = rf_sub.predict_proba(x_data_pred)[:, 1]\n",
    "# this_weeks_fights['Prediction_GB_SUB'] = gb_sub.predict_proba(x_data_pred)[:, 1]\n",
    "# this_weeks_fights['Prediction_LR_SUB'] = lr_sub.predict_proba(x_data_pred)[:, 1]\n",
    "# this_weeks_fights['Prediction_RF_KO'] = rf_ko.predict_proba(x_data_pred)[:, 1]\n",
    "# this_weeks_fights['Prediction_GB_KO'] = gb_ko.predict_proba(x_data_pred)[:, 1]\n",
    "# this_weeks_fights['Prediction_LR_KO'] = lr_ko.predict_proba(x_data_pred)[:, 1]\n",
    "\n",
    "# Saving date and predicted data\n",
    "this_weeks_fights['Date'] = dt.date.today()\n",
    "\n",
    "this_weeks_predictions = this_weeks_fights.copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3202648e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_39557/3877886165.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  predictions = predictions.append(this_weeks_predictions)\n"
     ]
    }
   ],
   "source": [
    "# Appending this week's predictions\n",
    "\n",
    "predictions = pd.read_csv('mma_data_predictions.csv', index_col = 0)\n",
    "predictions = predictions.append(this_weeks_predictions)\n",
    "predictions.reset_index(inplace = True, drop = True)\n",
    "predictions.to_csv('mma_data_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ef12ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating this week's bets\n",
    "\n",
    "prediction_df = this_weeks_predictions.copy()\n",
    "\n",
    "# Instantiating webdriver\n",
    "driver = webdriver.Safari()\n",
    "driver.get('https://www.actionnetwork.com/ufc/odds')\n",
    "# driver.maximize_window()\n",
    "\n",
    "# Getting odds table and formatting\n",
    "html = driver.page_source\n",
    "tables = pd.read_html(html)\n",
    "odds = tables[0]\n",
    "odds = odds.iloc[::2]\n",
    "odds.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# Iterating through to get each fighter's odds\n",
    "odds_df = pd.DataFrame(columns = ['Fighter_1', 'Fighter_2', 'Fighter_1_Odds', 'Fighter_2_Odds'])\n",
    "fighter_2_regex = r'^[A-Za-z]+\\s[A-Za-z]+'\n",
    "fighter_1_regex = r'[A-Za-z]+\\s[A-Za-z]+(?=[A-Za-z]*\\.)'\n",
    "flag_regex = r'[^\\x00-\\x7F]'\n",
    "for index, row in odds.iterrows():\n",
    "    # Getting fighter names\n",
    "    names_string = re.sub(flag_regex, '', row.Scheduled)\n",
    "    names_split = names_string.split()\n",
    "    if len(names_split) == 5:\n",
    "        fighter_2 = names_split[0] + ' ' + names_split[1][:-2]\n",
    "        # Splitting middle part to get fighter 1 first name\n",
    "        need_to_split = names_split[2]\n",
    "        split = re.findall('[A-Z][^A-Z]*', need_to_split)\n",
    "        fighter_1 = split[1] + ' ' + names_split[-1]\n",
    "    else:\n",
    "        # Case where first name is two names\n",
    "        try:\n",
    "            need_to_split = names_split[1]\n",
    "            split = re.findall('[A-Z][^A-Z]*', need_to_split)\n",
    "            fighter_2 = names_split[0] + ' ' + split[0]\n",
    "            if re.findall('[A-Z][^A-Z]*', names_split[1])[1][1] == '.': \n",
    "                # Case where second name is three names\n",
    "                if len(re.findall('[A-Z][^A-Z]*', names_split[2])) > 1:\n",
    "                    need_to_split = names_split[2]\n",
    "                    split = re.findall('[A-Z][^A-Z]*', need_to_split)\n",
    "                    fighter_1 = split[1] + ' ' + names_split[3] + ' ' + names_split[-1]\n",
    "        except:\n",
    "            # Case where first name is three names\n",
    "            if len(re.findall('[A-Z][^A-Z]*', names_split[2])) > 1:\n",
    "                need_to_split = names_split[2]\n",
    "                split = re.findall('[A-Z][^A-Z]*', need_to_split)\n",
    "                fighter_2 = names_split[0] + ' ' + names_split[1] + ' ' + split[0]\n",
    "                # Case where second name is two names\n",
    "                try:\n",
    "                    if len(names_split) == 7:\n",
    "                        if re.findall('[A-Z][^A-Z]*', names_split[-2])[1][1] == '.':\n",
    "                            need_to_split = names_split[4]\n",
    "                            split = re.findall('[A-Z][^A-Z]*', need_to_split)\n",
    "                            fighter_1 = split[1] + ' ' + names_split[-1]\n",
    "                    else:\n",
    "                        if re.findall('[A-Z][^A-Z]*', names_split[-2])[1][1] == '.':\n",
    "                            need_to_split = names_split[3]\n",
    "                            split = re.findall('[A-Z][^A-Z]*', need_to_split)\n",
    "                            fighter_1 = split[1] + ' ' + names_split[-1]\n",
    "                except:\n",
    "                    # Case where second name is three names\n",
    "                    if len(re.findall('[A-Z][^A-Z]*', names_split[6])) > 1:\n",
    "                        need_to_split = names_split[4]\n",
    "                        split = re.findall('[A-Z][^A-Z]*', need_to_split)\n",
    "                        fighter_1 = split[1] + ' ' + names_split[5] + ' ' + names_split[-1]\n",
    "                    # Case where second name is four names\n",
    "                    else:\n",
    "                        need_to_split = names_split[4]\n",
    "                        split = re.findall('[A-Z][^A-Z]*', need_to_split)\n",
    "                        fighter_1 = split[1] + ' ' + names_split[5] + ' ' + names_split[6] + ' ' + names_split[-1]\n",
    "            # Case where first name is four names\n",
    "            else:\n",
    "                need_to_split = names_split[3]\n",
    "                split = re.findall('[A-Z][^A-Z]*', need_to_split)\n",
    "                fighter_2 = names_split[0] + ' ' + names_split[1] + ' ' + names_split[2] + ' ' + split[0]\n",
    "                # Case where second name is two names\n",
    "                try:\n",
    "                    if re.findall('[A-Z][^A-Z]*', names_split[-2])[1][1] == '.':\n",
    "                        need_to_split = names_split[-3]\n",
    "                        split = re.findall('[A-Z][^A-Z]*', need_to_split)\n",
    "                        fighter_1 = split[1] +  ' ' + names_split[-1]\n",
    "                except:\n",
    "                    # Case where second name is three names\n",
    "                    if len(re.findall('[A-Z][^A-Z]*', names_split[7])) > 1:\n",
    "                        need_to_split = names_split[4]\n",
    "                        split = re.findall('[A-Z][^A-Z]*', need_to_split)\n",
    "                        fighter_1 = split[1] + ' ' + names_split[6] + ' ' + names_split[-1]\n",
    "                    # Case where second name is four names\n",
    "                    else:\n",
    "                        need_to_split = names_split[5]\n",
    "                        split = re.findall('[A-Z][^A-Z]*', need_to_split)\n",
    "                        fighter_1 = split[1] + ' ' + names_split[6] + ' ' + names_split[7] + ' ' + names_split[-1]\n",
    "    # Getting fighter odds\n",
    "    ml_string = row['Best Odds']\n",
    "    if len(ml_string) == 8:\n",
    "        ml_fighter_2 = ml_string[:4]\n",
    "        ml_fighter_1 = ml_string[-4:]\n",
    "    elif len(ml_string) == 9:\n",
    "        if (ml_string[4] == '+') | (ml_string[4]=='-'):\n",
    "            ml_fighter_2 = ml_string[:4]\n",
    "            ml_fighter_1 = ml_string[-5:]\n",
    "        else:\n",
    "            ml_fighter_2 = ml_string[:5]\n",
    "            ml_fighter_1 = ml_string[-4:]\n",
    "    elif len(ml_string) == 10:\n",
    "            ml_fighter_2 = ml_string[:5]\n",
    "            ml_fighter_1 = ml_string[-5:]\n",
    "    else:\n",
    "        continue\n",
    "    try:\n",
    "        ml_fighter_2 = float(ml_fighter_2)\n",
    "    except:\n",
    "        continue\n",
    "    try:\n",
    "        ml_fighter_1 = float(ml_fighter_1)\n",
    "    except:\n",
    "        continue\n",
    "    # Adding data to odds df\n",
    "    new_data = [fighter_1, fighter_2, ml_fighter_1, ml_fighter_2]\n",
    "    new_df = pd.DataFrame([new_data])\n",
    "    new_df.columns = odds_df.columns\n",
    "    odds_df = pd.concat([odds_df, new_df], ignore_index = True)\n",
    "\n",
    "# Calculating GB bets\n",
    "odds_df['Prediction_GB_Winner'] = 0\n",
    "for index, row in odds_df.iterrows():\n",
    "    prediction_df['FUZZ_1'] = prediction_df.fighter_1.apply(lambda x: fuzz.ratio(x, row.Fighter_1))\n",
    "    prediction_df['FUZZ_2'] = prediction_df.fighter_1.apply(lambda x: fuzz.ratio(x, row.Fighter_2))\n",
    "    try:\n",
    "        correct_row = prediction_df.loc[(prediction_df.FUZZ_1 > 50) | (prediction_df.FUZZ_2 > 50)].tail(1)\n",
    "        gb = correct_row['Prediction_GB_Winner'].values[0]\n",
    "        if correct_row['FUZZ_1'].values[0] > 50:\n",
    "            pass\n",
    "        else:\n",
    "            gb = 1.0 - gb\n",
    "        fights_1 = correct_row['wins_1'].values[0] + correct_row['losses_1'].values[0]\n",
    "        fights_2 = correct_row['wins_2'].values[0] + correct_row['losses_2'].values[0]\n",
    "        if (fights_1 > best_fight_number) | (fights_2 > best_fight_number):\n",
    "            odds_df.loc[index, 'Prediction_GB_Winner'] = gb\n",
    "        else:\n",
    "            continue\n",
    "    except:\n",
    "        continue\n",
    "odds_df['Bet_GB'] = odds_df.apply(calculate_bets_gb, diff = best_diff, axis = 1)\n",
    "# Calculating LGBM bets\n",
    "odds_df['Prediction_LGBM_Winner'] = 0\n",
    "for index, row in odds_df.iterrows():\n",
    "    prediction_df['FUZZ_1'] = prediction_df.fighter_1.apply(lambda x: fuzz.ratio(x, row.Fighter_1))\n",
    "    prediction_df['FUZZ_2'] = prediction_df.fighter_1.apply(lambda x: fuzz.ratio(x, row.Fighter_2))\n",
    "    try:\n",
    "        correct_row = prediction_df.loc[(prediction_df.FUZZ_1 > 50) | (prediction_df.FUZZ_2 > 50)].tail(1)\n",
    "        gb = correct_row['Prediction_LGBM_Winner'].values[0]\n",
    "        if correct_row['FUZZ_1'].values[0] > 50:\n",
    "            pass\n",
    "        else:\n",
    "            gb = 1.0 - gb\n",
    "        fights_1 = correct_row['wins_1'].values[0] + correct_row['losses_1'].values[0]\n",
    "        fights_2 = correct_row['wins_2'].values[0] + correct_row['losses_2'].values[0]\n",
    "        if (fights_1 > best_fight_number_lgbm) | (fights_2 > best_fight_number_lgbm):\n",
    "            odds_df.loc[index, 'Prediction_LGBM_Winner'] = gb\n",
    "        else:\n",
    "            continue\n",
    "    except:\n",
    "        continue\n",
    "odds_df['Bet_LGBM'] = odds_df.apply(calculate_bets_lgbm, axis = 1)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "this_weeks_bets = odds_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd94d737",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xz/nv9k4jpn7l9dtk4l7yqbl8640000gn/T/ipykernel_39557/158948969.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  mma_data = mma_data.append(this_weeks_bets)\n"
     ]
    }
   ],
   "source": [
    "# Appending this weeks bets\n",
    "\n",
    "mma_data = pd.read_csv('mma_bets.csv', index_col = 0)\n",
    "mma_data = mma_data.append(this_weeks_bets)\n",
    "mma_data.reset_index(inplace = True, drop = True)\n",
    "mma_data.to_csv('mma_bets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2adec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
